{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source: https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of this Analysis :  \n",
    "We read in the reduced train and test data sets containg APS Failure data obtained from the previous data cleaning stage. We then impute the missing values with three strategies resulting in 3 sets of train and test data. For each of them, we then find out the highly correlated variables and drop them from the file, to create the files ready for modelling the classification.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the reduced data set obtained after dropping columns that have missing values and low variance.\n",
    "train_data = pd.read_csv(\"train_reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in test data corresponding to the reduced train data \n",
    "test_data = pd.read_csv(\"test_reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Data columns (total 62 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   class   60000 non-null  object \n",
      " 1   ag_003  59329 non-null  float64\n",
      " 2   ag_004  59329 non-null  float64\n",
      " 3   ag_005  59329 non-null  float64\n",
      " 4   ag_006  59329 non-null  float64\n",
      " 5   ag_007  59329 non-null  float64\n",
      " 6   ah_000  59355 non-null  float64\n",
      " 7   al_000  59358 non-null  float64\n",
      " 8   am_0    59371 non-null  float64\n",
      " 9   an_000  59358 non-null  float64\n",
      " 10  ao_000  59411 non-null  float64\n",
      " 11  ap_000  59358 non-null  float64\n",
      " 12  aq_000  59411 non-null  float64\n",
      " 13  ay_001  59329 non-null  float64\n",
      " 14  ay_005  59329 non-null  float64\n",
      " 15  ay_006  59329 non-null  float64\n",
      " 16  ay_007  59329 non-null  float64\n",
      " 17  ay_008  59329 non-null  float64\n",
      " 18  az_003  59329 non-null  float64\n",
      " 19  az_004  59329 non-null  float64\n",
      " 20  az_005  59329 non-null  float64\n",
      " 21  az_006  59329 non-null  float64\n",
      " 22  ba_000  59312 non-null  float64\n",
      " 23  ba_001  59312 non-null  float64\n",
      " 24  ba_002  59312 non-null  float64\n",
      " 25  ba_003  59312 non-null  float64\n",
      " 26  ba_004  59312 non-null  float64\n",
      " 27  ba_006  59312 non-null  float64\n",
      " 28  ba_007  59312 non-null  float64\n",
      " 29  bb_000  59355 non-null  float64\n",
      " 30  bg_000  59358 non-null  float64\n",
      " 31  bi_000  59411 non-null  float64\n",
      " 32  bj_000  59411 non-null  float64\n",
      " 33  bp_000  12260 non-null  float64\n",
      " 34  bq_000  11278 non-null  float64\n",
      " 35  br_000  10736 non-null  float64\n",
      " 36  bu_000  59309 non-null  float64\n",
      " 37  bv_000  59309 non-null  float64\n",
      " 38  bx_000  56743 non-null  float64\n",
      " 39  cc_000  56745 non-null  float64\n",
      " 40  ci_000  59662 non-null  float64\n",
      " 41  cj_000  59662 non-null  float64\n",
      " 42  ck_000  59662 non-null  float64\n",
      " 43  cn_002  59313 non-null  float64\n",
      " 44  cn_003  59313 non-null  float64\n",
      " 45  cn_004  59313 non-null  float64\n",
      " 46  cn_005  59313 non-null  float64\n",
      " 47  cn_006  59313 non-null  float64\n",
      " 48  cq_000  59309 non-null  float64\n",
      " 49  cs_002  59331 non-null  float64\n",
      " 50  cs_003  59331 non-null  float64\n",
      " 51  cs_004  59331 non-null  float64\n",
      " 52  cs_005  59331 non-null  float64\n",
      " 53  cs_006  59331 non-null  float64\n",
      " 54  ee_000  59329 non-null  float64\n",
      " 55  ee_001  59329 non-null  float64\n",
      " 56  ee_002  59329 non-null  float64\n",
      " 57  ee_003  59329 non-null  float64\n",
      " 58  ee_004  59329 non-null  float64\n",
      " 59  ee_005  59329 non-null  float64\n",
      " 60  ee_006  59329 non-null  float64\n",
      " 61  ee_007  59329 non-null  float64\n",
      "dtypes: float64(61), object(1)\n",
      "memory usage: 28.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Data columns (total 62 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   class   16000 non-null  object \n",
      " 1   ag_003  15811 non-null  float64\n",
      " 2   ag_004  15811 non-null  float64\n",
      " 3   ag_005  15811 non-null  float64\n",
      " 4   ag_006  15811 non-null  float64\n",
      " 5   ag_007  15811 non-null  float64\n",
      " 6   ah_000  15825 non-null  float64\n",
      " 7   al_000  15831 non-null  float64\n",
      " 8   am_0    15837 non-null  float64\n",
      " 9   an_000  15831 non-null  float64\n",
      " 10  ao_000  15838 non-null  float64\n",
      " 11  ap_000  15831 non-null  float64\n",
      " 12  aq_000  15838 non-null  float64\n",
      " 13  ay_001  15808 non-null  float64\n",
      " 14  ay_005  15808 non-null  float64\n",
      " 15  ay_006  15808 non-null  float64\n",
      " 16  ay_007  15808 non-null  float64\n",
      " 17  ay_008  15808 non-null  float64\n",
      " 18  az_003  15808 non-null  float64\n",
      " 19  az_004  15808 non-null  float64\n",
      " 20  az_005  15808 non-null  float64\n",
      " 21  az_006  15808 non-null  float64\n",
      " 22  ba_000  15807 non-null  float64\n",
      " 23  ba_001  15807 non-null  float64\n",
      " 24  ba_002  15807 non-null  float64\n",
      " 25  ba_003  15807 non-null  float64\n",
      " 26  ba_004  15807 non-null  float64\n",
      " 27  ba_006  15807 non-null  float64\n",
      " 28  ba_007  15807 non-null  float64\n",
      " 29  bb_000  15825 non-null  float64\n",
      " 30  bg_000  15831 non-null  float64\n",
      " 31  bi_000  15838 non-null  float64\n",
      " 32  bj_000  15838 non-null  float64\n",
      " 33  bp_000  3279 non-null   float64\n",
      " 34  bq_000  3019 non-null   float64\n",
      " 35  br_000  2871 non-null   float64\n",
      " 36  bu_000  15810 non-null  float64\n",
      " 37  bv_000  15810 non-null  float64\n",
      " 38  bx_000  15134 non-null  float64\n",
      " 39  cc_000  15135 non-null  float64\n",
      " 40  ci_000  15914 non-null  float64\n",
      " 41  cj_000  15914 non-null  float64\n",
      " 42  ck_000  15914 non-null  float64\n",
      " 43  cn_002  15806 non-null  float64\n",
      " 44  cn_003  15806 non-null  float64\n",
      " 45  cn_004  15806 non-null  float64\n",
      " 46  cn_005  15806 non-null  float64\n",
      " 47  cn_006  15806 non-null  float64\n",
      " 48  cq_000  15810 non-null  float64\n",
      " 49  cs_002  15811 non-null  float64\n",
      " 50  cs_003  15811 non-null  float64\n",
      " 51  cs_004  15811 non-null  float64\n",
      " 52  cs_005  15811 non-null  float64\n",
      " 53  cs_006  15811 non-null  float64\n",
      " 54  ee_000  15808 non-null  float64\n",
      " 55  ee_001  15808 non-null  float64\n",
      " 56  ee_002  15808 non-null  float64\n",
      " 57  ee_003  15808 non-null  float64\n",
      " 58  ee_004  15808 non-null  float64\n",
      " 59  ee_005  15808 non-null  float64\n",
      " 60  ee_006  15808 non-null  float64\n",
      " 61  ee_007  15808 non-null  float64\n",
      "dtypes: float64(61), object(1)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "br_000    49264\n",
       "bq_000    48722\n",
       "bp_000    47740\n",
       "bx_000     3257\n",
       "cc_000     3255\n",
       "          ...  \n",
       "bj_000      589\n",
       "ci_000      338\n",
       "cj_000      338\n",
       "ck_000      338\n",
       "class         0\n",
       "Length: 62, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25    669.0\n",
       "0.50    671.0\n",
       "0.75    687.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum().quantile([0.25,0.5,0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ba_000      688\n",
       "ba_001      688\n",
       "ba_002      688\n",
       "ba_003      688\n",
       "ba_004      688\n",
       "ba_006      688\n",
       "ba_007      688\n",
       "bp_000    47740\n",
       "bq_000    48722\n",
       "br_000    49264\n",
       "bu_000      691\n",
       "bv_000      691\n",
       "bx_000     3257\n",
       "cc_000     3255\n",
       "cq_000      691\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = train_data.isnull().sum()\n",
    "x[x > 687]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the columns have missing values with in 700 . There are 5 columns with missing values in the range of 3000 and 40000 . We can drop these columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['bp_000', 'bq_000', 'br_000','bx_000','cc_000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(cols_to_drop, axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 57)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop the corresponding columns in test \n",
    "test_data.drop(cols_to_drop, axis = 1 , inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 57)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategies for imputation :\n",
    "1. Impute with zero value , drop the highly correlated columns.  \n",
    "2. Impute with mean/median , , drop the highly correlated columns.  \n",
    "3. Impute with knn, , drop the highly correlated columns.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Impute with zero value \n",
    "train_data_1 = train_data.copy()\n",
    "train_data_1.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train_data_1.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find out the highly correlated variables \n",
    "# Create correlation matrix\n",
    "corr_matrix = train_data_1.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No of columns that are correlated : 24\n"
     ]
    }
   ],
   "source": [
    "print(\" No of columns that are correlated : {}\".format(len(to_drop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1.drop(to_drop, axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the file \n",
    "train_data_1.to_csv(\"train_data_1.csv\" , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 33)\n"
     ]
    }
   ],
   "source": [
    "## impute the test data with zero and drop the columns as above.\n",
    "test_data_1 = test_data.copy()\n",
    "test_data_1.fillna(0, inplace = True)\n",
    "test_data_1.drop(to_drop, axis = 1 , inplace = True)\n",
    "print(test_data_1.shape)\n",
    "## save the file \n",
    "test_data_1.to_csv(\"test_data_1.csv\" , index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imputing with median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## impute the train and test daya with median values.\n",
    "\n",
    "train_data_2 = train_data.copy()\n",
    "test_data_2 = test_data.copy()\n",
    "\n",
    "cols = train_data_2.columns.tolist()\n",
    "from sklearn.impute import SimpleImputer\n",
    "si = SimpleImputer(strategy = 'median')\n",
    "train_data_2[cols[1:]] = si.fit_transform(train_data_2[cols[1:]])\n",
    "##\n",
    "si = SimpleImputer(strategy = 'median')\n",
    "test_data_2[cols[1:]] = si.fit_transform(test_data_2[cols[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data_2.isnull().sum() > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_data_2.isnull().sum() > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of correlated columns : 24\n"
     ]
    }
   ],
   "source": [
    "## Find out the highly correlated variables \n",
    "# Create correlation matrix\n",
    "corr_matrix = train_data_2.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop_2 = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "print(\"No of correlated columns : {}\".format(len(to_drop_2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 33)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "train_data_2.drop(to_drop_2, axis = 1 , inplace = True)\n",
    "print(train_data_2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop the correspoinding columns in test_data_2.\n",
    "test_data_2.drop(to_drop_2, axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 33)\n"
     ]
    }
   ],
   "source": [
    "print(test_data_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the file \n",
    "train_data_2.to_csv(\"train_data_2.csv\", index = False)\n",
    "test_data_2.to_csv(\"test_data_2.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imputing with knn\n",
    "train_data_3 = train_data.copy()\n",
    "test_data_3 = test_data.copy()\n",
    "\n",
    "cols = train_data_3.columns.tolist()\n",
    "from sklearn.impute import KNNImputer\n",
    "knn_imp = KNNImputer(n_neighbors = 2)\n",
    "train_data_3[cols[1:]] = knn_imp.fit_transform(train_data_3[cols[1:]])\n",
    "##\n",
    "knn_imp = KNNImputer(n_neighbors = 2)\n",
    "test_data_3[cols[1:]] = knn_imp.fit_transform(test_data_3[cols[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of correlated columns : 24\n"
     ]
    }
   ],
   "source": [
    "## Find out the highly correlated variables \n",
    "# Create correlation matrix\n",
    "corr_matrix = train_data_3.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop_3 = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "print(\"No of correlated columns : {}\".format(len(to_drop_3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data_3.isnull().sum() > 0).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_data_3.isnull().sum() > 0).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 33)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "train_data_3.drop(to_drop_3, axis = 1 , inplace = True)\n",
    "print(train_data_3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 33)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "test_data_3.drop(to_drop_3, axis = 1 , inplace = True)\n",
    "print(test_data_3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the file \n",
    "train_data_3.to_csv(\"train_data_3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the test file\n",
    "test_data_3.to_csv(\"test_data_3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
